{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f85b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import resample\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3101904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    110\n",
      "1    105\n",
      "Name: emotion_group, dtype: int64\n",
      "Index(['an1_time14', 'an2_time14', 'an3_time14', 'ap1_time14', 'ap2_time14',\n",
      "       's1', 's2', 's3', 's4', 's5', 's6', 's7', 'hand', 'puberty', 'bmi14',\n",
      "       'ses', 'ctqabuse', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
      "       'PC8', 'mdd_mean', 'semotion_14', 'ctq_cutoff', 'emotion_group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Participants with above-median genetic risks for depression\n",
    "data = pd.read_csv('./high_genetic/data_predict_high_genetic.csv')\n",
    "print(data['emotion_group'].value_counts())\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48c5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, train_index, test_index):\n",
    "    train_data = data.iloc[train_index, :]\n",
    "    test_data = data.iloc[test_index, :]\n",
    "    all_colname = train_data.columns\n",
    "    # select variables\n",
    "    select_cols = list(all_colname[:16]) # for all factors + basic covariates\n",
    "\n",
    "    # childhood abuse\n",
    "    select_cols.append(all_colname[16])\n",
    "\n",
    "    # emotional symptoms at age 14\n",
    "    select_cols.append(all_colname[26])\n",
    "#     select_cols.append(all_colname[17])\n",
    "\n",
    "    # emotional disorders\n",
    "    select_cols.append(all_colname[28])\n",
    "#     select_cols.append(all_colname[18])\n",
    "    \n",
    "    train_data = train_data[select_cols]\n",
    "    test_data = test_data[select_cols]\n",
    "    \n",
    "    # Normalization\n",
    "    attr_list = select_cols[:5] + select_cols[13:-1] \n",
    "\n",
    "    # print(attr_list)\n",
    "    scaler_list = dict()\n",
    "    for i in attr_list:\n",
    "        tmp = train_data[i]\n",
    "        scaler = StandardScaler()\n",
    "        train_data[i] = scaler.fit_transform(tmp.to_numpy().reshape(-1, 1))\n",
    "        scaler_list[i] = scaler\n",
    "    for i in attr_list:\n",
    "        tmp_test = test_data[i]\n",
    "        scaler = scaler_list[i]\n",
    "        test_data[i] = scaler.transform(tmp_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "    train_x, train_y = train_data.drop('emotion_group', axis=1), train_data['emotion_group']\n",
    "    test_x, test_y = test_data.drop('emotion_group', axis=1), test_data['emotion_group']\n",
    "\n",
    "    train_x['interaction'] = [i * j for i, j in zip(train_x['ap1_time14'], train_x['ctqabuse'])]\n",
    "    test_x['interaction'] = [i * j for i, j in zip(test_x['ap1_time14'], test_x['ctqabuse'])]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd41b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(threshold, probabilities):\n",
    "    return [1 if prob > threshold else 0 for prob in probabilities] \n",
    "\n",
    "def get_fpr_tpr(y, prob):\n",
    "    roc_values = []\n",
    "    for thresh in np.linspace(0, 1, 40):\n",
    "        preds = get_preds(thresh, prob)\n",
    "        tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        fpr = fp / (fp + tn)\n",
    "        roc_values.append([tpr, fpr])\n",
    "    tpr_values, fpr_values = zip(*roc_values)\n",
    "    tpr_values = np.array(tpr_values)\n",
    "    fpr_values = np.array(fpr_values)\n",
    "\n",
    "    return tpr_values, fpr_values\n",
    "\n",
    "def prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=None, threshold=0.5, print_fpr=False):\n",
    "    if drop_features is not None:\n",
    "         train_x, test_x = train_x.drop(drop_features,axis=1), test_x.drop(drop_features,axis=1)  \n",
    "    \n",
    "    model = model_pre.fit(train_x, train_y)\n",
    "    y_pred = (model.predict_proba(test_x)[:, 1] > threshold).astype(bool)\n",
    "    y_pred_proba = model.predict_proba(test_x)[:, 1]\n",
    "    auc, recall = round(roc_auc_score(test_y, y_pred_proba), 4), recall_score(test_y, y_pred, average=None)\n",
    "    \n",
    "    if print_fpr:\n",
    "        tpr_values, fpr_values = get_fpr_tpr(test_y, y_pred_proba)\n",
    "        return auc, recall[0], recall[1], tpr_values, fpr_values\n",
    "    else:\n",
    "        return auc, recall[0], recall[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e4c65",
   "metadata": {},
   "source": [
    "**-------------- Prediction model for emotional disorders --------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d633cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################## 1 ##########################\n",
      "########################## 2 ##########################\n",
      "########################## 3 ##########################\n",
      "########################## 4 ##########################\n",
      "########################## 5 ##########################\n",
      "########################## 6 ##########################\n",
      "########################## 7 ##########################\n",
      "########################## 8 ##########################\n",
      "########################## 9 ##########################\n",
      "########################## 10 ##########################\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "# Repeat a 5-fold cross-validation 10 times\n",
    "total_auc = np.zeros((10, 5, 11))\n",
    "total_spe = np.zeros((10, 5, 11))\n",
    "total_sen = np.zeros((10, 5, 11))\n",
    "\n",
    "tpr_svm, fpr_svm, tpr_base, fpr_base = [], [], [], []\n",
    "\n",
    "for step in range(10):\n",
    "    print(f\"########################## {step + 1} ##########################\")\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#     model_pre= LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    "    model_pre = svm.SVC(kernel=\"linear\", probability=True, class_weight='balanced')\n",
    "\n",
    "    auc_result = np.zeros((5, 11))\n",
    "    spe_result = np.zeros((5, 11))\n",
    "    sen_result = np.zeros((5, 11))\n",
    "    \n",
    "    for num, (train_index, test_index) in enumerate(skf.split(data.drop('emotion_group', axis=1),  data['emotion_group'])):\n",
    "        \n",
    "        train_x, train_y, test_x, test_y = data_process(data, train_index, test_index)\n",
    "        \n",
    "        ###### all factors + interaction + abuse ########\n",
    "        auc_result[num, 0], spe_result[num, 0], sen_result[num, 0] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y)\n",
    "        \n",
    "        #### 3 factors + interaction + abuse ########\n",
    "        drop_features = ['an2_time14', 'an3_time14']\n",
    "        auc_result[num, 1], spe_result[num, 1], sen_result[num, 1] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 1 factors + interaction + absue ########\n",
    "        drop_features = ['an1_time14', 'an2_time14', 'an3_time14', 'ap2_time14']\n",
    "        auc_result[num, 2], spe_result[num, 2], sen_result[num, 2], tpr, fpr = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features, print_fpr=True)\n",
    "        \n",
    "        tpr_svm.append(tpr), fpr_svm.append(fpr)\n",
    "        \n",
    "        ##### all factors + absue ########\n",
    "        drop_features = ['interaction']\n",
    "        auc_result[num, 3], spe_result[num, 3], sen_result[num, 3] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 3 factors + abuse ########\"\n",
    "        drop_features = ['interaction', 'an2_time14', 'an3_time14']\n",
    "        auc_result[num, 4], spe_result[num, 4], sen_result[num, 4] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 1 factors + abuse ########\n",
    "        drop_features = ['interaction', 'an1_time14', 'an2_time14', 'an3_time14', 'ap2_time14']\n",
    "        auc_result[num, 5], spe_result[num, 5], sen_result[num, 5] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### all factors ########\n",
    "        drop_features = ['interaction', 'ctqabuse']\n",
    "        auc_result[num, 6], spe_result[num, 6], sen_result[num, 6] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 3 factors ########\n",
    "        drop_features = ['interaction', 'ctqabuse', 'an2_time14', 'an3_time14']\n",
    "        auc_result[num, 7], spe_result[num, 7], sen_result[num, 7] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 1 factors ########\n",
    "        drop_features = ['interaction', 'ctqabuse', 'an1_time14', 'an2_time14', 'an3_time14', 'ap2_time14']\n",
    "        auc_result[num, 8], spe_result[num, 8], sen_result[num, 8] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### abuse ########\n",
    "        drop_features = ['an1_time14', 'an2_time14', 'an3_time14', 'ap1_time14', 'ap2_time14','interaction']\n",
    "        auc_result[num, 9], spe_result[num, 9], sen_result[num, 9], tpr, fpr = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features, print_fpr=True)\n",
    "        tpr_base.append(tpr), fpr_base.append(fpr)\n",
    "        \n",
    "        ##### without ########\n",
    "        drop_features = ['an1_time14', 'an2_time14', 'an3_time14', 'ap1_time14', 'ap2_time14','ctqabuse', 'interaction']\n",
    "        auc_result[num, 10], spe_result[num, 10], sen_result[num, 10] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "       \n",
    "    total_auc[step] = auc_result\n",
    "    total_spe[step] = spe_result\n",
    "    total_sen[step] = sen_result\n",
    "\n",
    "total_auc = total_auc.reshape(50, 11)\n",
    "total_spe = total_spe.reshape(50, 11)\n",
    "total_sen = total_sen.reshape(50, 11)\n",
    "\n",
    "auc_pd = pd.DataFrame(total_auc, columns=['all_inter_abuse', 'three_inter_abuse', 'one_inter_abuse',\n",
    "                                         'all_abuse', 'three_abuse', 'one_abuse', 'all', 'three', 'one', \n",
    "                                         'baseline', 'without'])\n",
    "\n",
    "spe_pd = pd.DataFrame(total_spe, columns=['all_inter_abuse', 'three_inter_abuse', 'one_inter_abuse',\n",
    "                                         'all_abuse', 'three_abuse', 'one_abuse', 'all', 'three', 'one', \n",
    "                                         'baseline','without'])\n",
    "\n",
    "sen_pd = pd.DataFrame(total_sen, columns=['all_inter_abuse', 'three_inter_abuse', 'one_inter_abuse',\n",
    "                                         'all_abuse', 'three_abuse', 'one_abuse', 'all', 'three', 'one', \n",
    "                                         'baseline','without'])\n",
    "\n",
    "# print(\"############ AUC ###############\")\n",
    "# for column in auc_pd.columns:\n",
    "#         print(f'{column} | {auc_pd.mean()[column]} - {auc_pd.std()[column]}')\n",
    "        \n",
    "# print(\"############ Specificity ###############\")\n",
    "# for column in spe_pd.columns:\n",
    "#         print(f'{column} | {spe_pd.mean()[column]} - {spe_pd.std()[column]}')\n",
    "\n",
    "# print(\"############ Sensitivity ###############\")\n",
    "# for column in sen_pd.columns:\n",
    "#         print(f'{column} | {sen_pd.mean()[column]} - {sen_pd.std()[column]}')\n",
    "\n",
    "\n",
    "tpr_svm_m = np.array(tpr_svm).mean(axis=0)\n",
    "fpr_svm_m = np.array(fpr_svm).mean(axis=0)\n",
    "\n",
    "tpr_svm_sd = np.array(tpr_svm).std(axis=0)\n",
    "fpr_svm_sd = np.array(fpr_svm).std(axis=0)\n",
    "\n",
    "tpr_base_m = np.array(tpr_base).mean(axis=0)\n",
    "fpr_base_m = np.array(fpr_base).mean(axis=0)\n",
    "\n",
    "tpr_base_sd = np.array(tpr_base).std(axis=0)\n",
    "fpr_base_sd = np.array(fpr_base).std(axis=0)\n",
    "\n",
    "tpr_fpr_svm = np.stack((tpr_svm_m, fpr_svm_m, tpr_svm_sd, fpr_svm_sd), axis=1)\n",
    "tpr_fpr_base = np.stack((tpr_base_m, fpr_base_m, tpr_base_sd, fpr_base_sd), axis=1)\n",
    "\n",
    "tpr_fpr_svm = pd.DataFrame(tpr_fpr_svm, columns=['tpr_mean', 'fpr_mean', 'tpr_sd', 'fpr_sd'])\n",
    "tpr_fpr_base = pd.DataFrame(tpr_fpr_base, columns=['tpr_mean', 'fpr_mean', 'tpr_sd', 'fpr_sd'])\n",
    "\n",
    "\n",
    "# tpr_fpr_svm.to_csv('tpr_svm.csv', index=False)\n",
    "# tpr_fpr_base.to_csv('tpr_base.csv', index=False)\n",
    "# auc_pd.to_csv('high_auc_svm.csv', index=False)\n",
    "# spe_pd.to_csv('high_spe_svm.csv', index=False)\n",
    "# sen_pd.to_csv('high_sen_svm.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myTorch",
   "language": "python",
   "name": "mytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
