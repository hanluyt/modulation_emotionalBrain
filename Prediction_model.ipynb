{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f85b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import resample\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3101904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    110\n",
      "1    105\n",
      "Name: emotion_group, dtype: int64\n",
      "Index(['an1_time14', 'an2_time14', 'an3_time14', 'ap1_time14', 'ap2_time14',\n",
      "       's1', 's2', 's3', 's4', 's5', 's6', 's7', 'hand', 'puberty', 'bmi14',\n",
      "       'ses', 'ctqabuse', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7',\n",
      "       'PC8', 'mdd_mean', 'semotion_14', 'ctq_cutoff', 'emotion_group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Participants with above-median genetic risks for depression\n",
    "data = pd.read_csv('./high_genetic/data_predict_high_genetic.csv')\n",
    "print(data['emotion_group'].value_counts())\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48c5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, train_index, test_index):\n",
    "    train_data = data.iloc[train_index, :]\n",
    "    test_data = data.iloc[test_index, :]\n",
    "    all_colname = train_data.columns\n",
    "    # select variables\n",
    "    select_cols = list(all_colname[:16]) # for all factors + basic covariates\n",
    "\n",
    "    # childhood abuse\n",
    "    select_cols.append(all_colname[16])\n",
    "\n",
    "    # emotional symptoms at age 14\n",
    "    select_cols.append(all_colname[26])\n",
    "\n",
    "    # emotional disorders\n",
    "    select_cols.append(all_colname[28])\n",
    "\n",
    "    train_data = train_data[select_cols]\n",
    "    test_data = test_data[select_cols]\n",
    "    \n",
    "    # Normalization\n",
    "    attr_list = select_cols[:5] + select_cols[13:-1] \n",
    "\n",
    "    # print(attr_list)\n",
    "    scaler_list = dict()\n",
    "    for i in attr_list:\n",
    "        tmp = train_data[i]\n",
    "        scaler = StandardScaler()\n",
    "        train_data[i] = scaler.fit_transform(tmp.to_numpy().reshape(-1, 1))\n",
    "        scaler_list[i] = scaler\n",
    "    for i in attr_list:\n",
    "        tmp_test = test_data[i]\n",
    "        scaler = scaler_list[i]\n",
    "        test_data[i] = scaler.transform(tmp_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "    train_x, train_y = train_data.drop('emotion_group', axis=1), train_data['emotion_group']\n",
    "    test_x, test_y = test_data.drop('emotion_group', axis=1), test_data['emotion_group']\n",
    "\n",
    "    train_x['interaction'] = [i * j for i, j in zip(train_x['ap1_time14'], train_x['ctqabuse'])]\n",
    "    test_x['interaction'] = [i * j for i, j in zip(test_x['ap1_time14'], test_x['ctqabuse'])]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd41b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=None, threshold=0.5):\n",
    "    if drop_features is not None:\n",
    "         train_x, test_x = train_x.drop(drop_features,axis=1), test_x.drop(drop_features,axis=1)  \n",
    "    \n",
    "    model = model_pre.fit(train_x, train_y)\n",
    "    y_pred = (model.predict_proba(test_x)[:, 1] > threshold).astype(bool)\n",
    "    y_pred_proba = model.predict_proba(test_x)[:, 1]\n",
    "    auc, recall = round(roc_auc_score(test_y, y_pred_proba), 4), recall_score(test_y, y_pred, average=None)\n",
    "    \n",
    "    return auc, recall[0], recall[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e4c65",
   "metadata": {},
   "source": [
    "**-------------- Prediction model for emotional disorders --------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d633cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################## 1 ##########################\n",
      "########################## 2 ##########################\n",
      "########################## 3 ##########################\n",
      "########################## 4 ##########################\n",
      "########################## 5 ##########################\n",
      "########################## 6 ##########################\n",
      "########################## 7 ##########################\n",
      "########################## 8 ##########################\n",
      "########################## 9 ##########################\n",
      "########################## 10 ##########################\n",
      "############ AUC ###############\n",
      "all_inter_abuse | 0.7394379999999999 - 0.08136871958271565\n",
      "three_inter_abuse | 0.747402 - 0.07544314385749072\n",
      "one_inter_abuse | 0.7592619999999997 - 0.0750869669660672\n",
      "all_abuse | 0.7329859999999999 - 0.08145763644185777\n",
      "three_abuse | 0.7381840000000001 - 0.07790101086556932\n",
      "one_abuse | 0.749654 - 0.07684080338795349\n",
      "all | 0.7287939999999997 - 0.08786432818469017\n",
      "three | 0.7342019999999999 - 0.08590205027131964\n",
      "one | 0.745886 - 0.08434721729438456\n",
      "without | 0.7485299999999998 - 0.08461826948485913\n",
      "############ Specificity ###############\n",
      "all_inter_abuse | 0.6945454545454546 - 0.0976360837881169\n",
      "three_inter_abuse | 0.7027272727272728 - 0.10835014422113509\n",
      "one_inter_abuse | 0.7163636363636364 - 0.10041237288352055\n",
      "all_abuse | 0.6790909090909092 - 0.10527093605584532\n",
      "three_abuse | 0.6881818181818182 - 0.11359368400744028\n",
      "one_abuse | 0.6954545454545454 - 0.11143507988136699\n",
      "all | 0.6836363636363637 - 0.10468853643541093\n",
      "three | 0.6918181818181819 - 0.1044183303896856\n",
      "one | 0.6981818181818178 - 0.10581028858217496\n",
      "without | 0.7054545454545452 - 0.10069751675314355\n",
      "############ Sensitivity ###############\n",
      "all_inter_abuse | 0.6552380952380955 - 0.12490359093908573\n",
      "three_inter_abuse | 0.6704761904761908 - 0.11697515787866491\n",
      "one_inter_abuse | 0.6809523809523812 - 0.1183165110947353\n",
      "all_abuse | 0.6438095238095243 - 0.11831259974046078\n",
      "three_abuse | 0.6619047619047622 - 0.11831651109473527\n",
      "one_abuse | 0.6790476190476192 - 0.1145647710659854\n",
      "all | 0.6447619047619051 - 0.11946864325728448\n",
      "three | 0.6580952380952384 - 0.11081964640922282\n",
      "one | 0.664761904761905 - 0.11009484802255189\n",
      "without | 0.6666666666666669 - 0.11504445255297797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Repeat a 5-fold cross-validation 10 times\n",
    "total_auc = np.zeros((10, 5, 10))\n",
    "total_spe = np.zeros((10, 5, 10))\n",
    "total_sen = np.zeros((10, 5, 10))\n",
    "\n",
    "for step in range(10):\n",
    "    print(f\"########################## {step + 1} ##########################\")\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    model_pre= LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    "#   model_pre = svm.SVC(kernel=\"linear\", probability=True, class_weight='balanced')\n",
    "\n",
    "    auc_result = np.zeros((5, 10))\n",
    "    spe_result = np.zeros((5, 10))\n",
    "    sen_result = np.zeros((5, 10))\n",
    "    \n",
    "    for num, (train_index, test_index) in enumerate(skf.split(data.drop('emotion_group', axis=1),  data['emotion_group'])):\n",
    "        \n",
    "        train_x, train_y, test_x, test_y = data_process(data, train_index, test_index)\n",
    "        \n",
    "        ###### all factors + interaction + abuse ########\n",
    "        auc_result[num, 0], spe_result[num, 0], sen_result[num, 0] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y)\n",
    "        \n",
    "        ##### 3 factors + interaction + abuse ########\n",
    "        drop_features = ['an2_time14', 'an3_time14']\n",
    "        auc_result[num, 1], spe_result[num, 1], sen_result[num, 1] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 1 factors + interaction + absue ########\n",
    "        drop_features = ['an1_time14', 'an2_time14', 'an3_time14', 'ap2_time14']\n",
    "        auc_result[num, 2], spe_result[num, 2], sen_result[num, 2] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### all factors + absue ########\n",
    "        drop_features = ['interaction']\n",
    "        auc_result[num, 3], spe_result[num, 3], sen_result[num, 3] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 3 factors + abuse ########\"\n",
    "        drop_features = ['interaction', 'an2_time14', 'an3_time14']\n",
    "        auc_result[num, 4], spe_result[num, 4], sen_result[num, 4] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 1 factors + abuse ########\n",
    "        drop_features = ['interaction', 'an1_time14', 'an2_time14', 'an3_time14', 'ap2_time14']\n",
    "        auc_result[num, 5], spe_result[num, 5], sen_result[num, 5] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### all factors ########\n",
    "        drop_features = ['interaction', 'ctqabuse']\n",
    "        auc_result[num, 6], spe_result[num, 6], sen_result[num, 6] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 3 factors ########\n",
    "        drop_features = ['interaction', 'ctqabuse', 'an2_time14', 'an3_time14']\n",
    "        auc_result[num, 7], spe_result[num, 7], sen_result[num, 7] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### 1 factors ########\n",
    "        drop_features = ['interaction', 'ctqabuse', 'an1_time14', 'an2_time14', 'an3_time14', 'ap2_time14']\n",
    "        auc_result[num, 8], spe_result[num, 8], sen_result[num, 8] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "        ##### without ########\n",
    "        drop_features = ['an1_time14', 'an2_time14', 'an3_time14', 'ap1_time14', 'ap2_time14','ctqabuse', 'interaction']\n",
    "        auc_result[num, 9], spe_result[num, 9], sen_result[num, 9] = \\\n",
    "        prediction(model_pre, train_x, train_y, test_x, test_y, drop_features=drop_features)\n",
    "        \n",
    "    \n",
    "    total_auc[step] = auc_result\n",
    "    total_spe[step] = spe_result\n",
    "    total_sen[step] = sen_result\n",
    "\n",
    "total_auc = total_auc.reshape(50, 10)\n",
    "total_spe = total_spe.reshape(50, 10)\n",
    "total_sen = total_sen.reshape(50, 10)\n",
    "\n",
    "auc_pd = pd.DataFrame(total_auc, columns=['all_inter_abuse', 'three_inter_abuse', 'one_inter_abuse',\n",
    "                                         'all_abuse', 'three_abuse', 'one_abuse', 'all', 'three', 'one', \n",
    "                                         'without'])\n",
    "\n",
    "spe_pd = pd.DataFrame(total_spe, columns=['all_inter_abuse', 'three_inter_abuse', 'one_inter_abuse',\n",
    "                                         'all_abuse', 'three_abuse', 'one_abuse', 'all', 'three', 'one', \n",
    "                                         'without'])\n",
    "\n",
    "sen_pd = pd.DataFrame(total_sen, columns=['all_inter_abuse', 'three_inter_abuse', 'one_inter_abuse',\n",
    "                                         'all_abuse', 'three_abuse', 'one_abuse', 'all', 'three', 'one', \n",
    "                                         'without'])\n",
    "\n",
    "print(\"############ AUC ###############\")\n",
    "for column in auc_pd.columns:\n",
    "        print(f'{column} | {auc_pd.mean()[column]} - {auc_pd.std()[column]}')\n",
    "        \n",
    "print(\"############ Specificity ###############\")\n",
    "for column in spe_pd.columns:\n",
    "        print(f'{column} | {spe_pd.mean()[column]} - {spe_pd.std()[column]}')\n",
    "\n",
    "print(\"############ Sensitivity ###############\")\n",
    "for column in sen_pd.columns:\n",
    "        print(f'{column} | {sen_pd.mean()[column]} - {sen_pd.std()[column]}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myTorch",
   "language": "python",
   "name": "mytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
